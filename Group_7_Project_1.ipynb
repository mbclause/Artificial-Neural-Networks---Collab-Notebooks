{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPFfBHWvjalY"
      },
      "source": [
        "Project 1 - Group 7\n",
        "\n",
        "Author: **Behzad Hosseini**, **Raffay Ahmed**, **Nick Bidler**, **Michael Clausen**, **Kristopher Curry**, **Janvier Uwase**,\n",
        "\n",
        "Course: **Artificial Neural Network**\n",
        "\n",
        "Section: **01**\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Xr6Or4Z3rN_"
      },
      "source": [
        "# Project 1\n",
        "\n",
        "For this project, our group worked with creating a convolutional neural network that is capable of recognizing hand-written letters. We also explored transfer learning during the last phase of this project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8efa6ZzC4Oq3"
      },
      "source": [
        "# Global Imports\n",
        "\n",
        "Below, we set up many of the environment variables that we needed for the duration of the project.\n",
        "\n",
        "The first important decision that we made was to use keras over pytorch, since the majority of our team had more experience with keras. The second decision was that we decided to set up a shared Google Drive in order to dump data, models, and logs. Since the CSUF Google Account did not allow us to set up a shared google drive, we used an external account that one of our team members possessed to create the drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9uv5n2HpjM_E",
        "outputId": "77f439ee-479e-4caa-b113-1071e16e7d43"
      },
      "outputs": [
        {
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-79ff960af28c>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# mount google drive to store and retrieve data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    127\u001b[0m   )\n\u001b[1;32m    128\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# Check if the tensorboard extension is already loaded\n",
        "if 'tensorboard' not in get_ipython().extension_manager.loaded:\n",
        "    # Load the TensorBoard extension if it's not loaded\n",
        "    %load_ext tensorboard\n",
        "else:\n",
        "    # Reload the TensorBoard extension if it's already loaded\n",
        "    %reload_ext tensorboard\n",
        "\n",
        "from IPython.display import display\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import datetime, os\n",
        "import string\n",
        "import shutil\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# mount google drive to store and retrieve data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "data_dir = \"/content/drive/Shareddrives/csuf-585-p1-g7/Data\"\n",
        "models_dir = \"/content/drive/Shareddrives/csuf-585-p1-g7/Models\"\n",
        "logs_dir = \"/content/drive/Shareddrives/csuf-585-p1-g7/Logs\"\n",
        "\n",
        "\n",
        "# Set random seed\n",
        "seed = 1234\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# Check if GPU is available\n",
        "if tf.test.gpu_device_name():\n",
        "  device = tf.device('GPU')\n",
        "  print('Using GPU:', tf.test.gpu_device_name())\n",
        "else:\n",
        "  device = tf.device('CPU')\n",
        "  print('Using CPU')\n",
        "\n",
        "print(f\"Tensorflow version: {tf.__version__}\")\n",
        "print(f\"Keras version: {keras.__version__}\")\n",
        "\n",
        "# A dictionary of labels in EMNIST letters dataset\n",
        "emnist_labels = {i: letter for i, letter in enumerate(string.ascii_uppercase)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZV7hdn0cHp8"
      },
      "source": [
        "# Helper Functions\n",
        "\n",
        "Below we create some other helper functions to clean up our code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oizMiwkbb1mq"
      },
      "outputs": [],
      "source": [
        "# remove all files and directories in the directory\n",
        "def remove_dir_contents(dir_path):\n",
        "  for file in os.listdir(dir_path):\n",
        "      file_path = os.path.join(dir_path, file)\n",
        "      try:\n",
        "          if os.path.isfile(file_path):\n",
        "              os.remove(file_path)\n",
        "          elif os.path.isdir(file_path):\n",
        "              shutil.rmtree(file_path)\n",
        "      except Exception as e:\n",
        "          print(e)\n",
        "\n",
        "\n",
        "def visualize_image(image, label):\n",
        "  # Visualize an image in the dataset\n",
        "  plt.imshow(image, cmap='gray')\n",
        "\n",
        "  # Get the original label\n",
        "  original_label = np.argmax(label)\n",
        "\n",
        "  print(f\"Label (Lowercase | Uppercase) = {emnist_labels[original_label]}\")\n",
        "\n",
        "\n",
        "# Load emnist dataset and return various sets after removing unused class\n",
        "def emnist_load_data():\n",
        "  with np.load(os.path.join(data_dir, \"emnist_letters.npz\")) as f:\n",
        "    (train_images, train_labels) = f[\"train_images\"], f[\"train_labels\"]\n",
        "    (validate_images, validate_labels) = f[\"validate_images\"], f[\"validate_labels\"]\n",
        "    (test_images, test_labels) = f[\"test_images\"], f[\"test_labels\"]\n",
        "\n",
        "  # Remove first class (index 0)\n",
        "  train_labels = np.delete(train_labels, 0, axis=1)\n",
        "\n",
        "  validate_labels = np.delete(validate_labels, 0, axis=1)\n",
        "\n",
        "  test_labels = np.delete(test_labels, 0, axis=1)\n",
        "\n",
        "  return (train_images, train_labels), (validate_images, validate_labels), (test_images, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmdLeDcLGX2a"
      },
      "source": [
        "# Part 1 - Warm-Up\n",
        "\n",
        "During part 1, we mainly focused on running other datasets (Multilayer Perceptron, MNIST, and EMNIST). We had to document the accuracies as well throughout."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwmSLfAYJdm-"
      },
      "source": [
        "## Question 1\n",
        "Open this notebook by Francois Chollet, which creates a simple Multilayer Perceptron as described in Section 2.1 of Deep Learning with Python, Second Edition. (Recall that this book is available from the library’s O’Reilly database.)\n",
        "Chollet’s example uses the simpler MNIST dataset, which includes only handwritten digits. That dataset is included with Keras.\n",
        "Run the model from this notebook. What accuracy does it achieve for MNIST?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRm9Fd_PG85b"
      },
      "source": [
        "**Loading the MNIST dataset in Keras**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WSnoS0rwGZUP"
      },
      "outputs": [],
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qyT8drruHUq9"
      },
      "outputs": [],
      "source": [
        "print(f\"train_images.shape  =  {train_images.shape}\\n\")\n",
        "print(f\"len(train_labels)  =  {len(train_labels)}\\n\")\n",
        "print(f\"train_labels  =  {train_labels}\\n\")\n",
        "print(f\"test_images.shape  =  {test_images.shape}\\n\")\n",
        "print(f\"len(test_labels)  =  {len(test_labels)}\\n\")\n",
        "print(f\"test_labels  =  {test_labels}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u31-2Q-JH59c"
      },
      "source": [
        "**The network architecture**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3D_N_wAqH6a9"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3ZVfVfWH9YX"
      },
      "source": [
        "**The compilation step**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XNFatQZTH949"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_84fH8NDIAfl"
      },
      "source": [
        "**Preparing the image data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EpJwOjA9IBVH"
      },
      "outputs": [],
      "source": [
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype(\"float32\") / 255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2_9LrTrIDuR"
      },
      "source": [
        "**\"Fitting\" the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aoVcx9d5ICij"
      },
      "outputs": [],
      "source": [
        "history_part1 = model.fit(train_images, train_labels, epochs=5, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZmxHPPZB5-PA"
      },
      "outputs": [],
      "source": [
        "## Visualize the accuracy and loss\n",
        "\n",
        "plt.plot(history_part1.history['accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history_part1.history['loss'], color='red')\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJ9QNxzt7r5q"
      },
      "source": [
        "Note on results: We noticed that the loss curve isn't as smooth (seems to be 3 different linear segments)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_23QpEkIIst"
      },
      "source": [
        "**Using the model to make predictions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RfxQK06vIJN5"
      },
      "outputs": [],
      "source": [
        "test_digits = test_images[0:10]\n",
        "predictions = model.predict(test_digits)\n",
        "\n",
        "print(f\"predictions[0]  =  {predictions[0]}\\n\")\n",
        "print(f\"predictions[0].argmax()  =  {predictions[0].argmax()}\\n\")\n",
        "print(f\"predictions[0][7]  =  {predictions[0][7]}\\n\")\n",
        "print(f\"test_labels[0]  =  {test_labels[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdSxSm39Ii2d"
      },
      "source": [
        "**Evaluating the model on new data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rC0qQCZQIjSJ"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f\"test_acc: {test_acc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9zN4HaSJmRv"
      },
      "source": [
        "## Answer to question 1:\n",
        "As it can be seen, the accuracy on the test set is 98%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_IO0YH1KW20"
      },
      "source": [
        "## Question 2 and Question 3\n",
        "Load the EMNIST Letters dataset, and use plt.imshow() to verify that the image data has been loaded correctly and that the corresponding labels are correct."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "139Y7K6MTVuM"
      },
      "source": [
        "**Loading the EMNIST letters dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PO3ojlksKaSn"
      },
      "outputs": [],
      "source": [
        "(train_images, train_labels), (validate_images, validate_labels), (test_images, test_labels) = emnist_load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1YaZud_iQs2d"
      },
      "outputs": [],
      "source": [
        "print(\"------------------------------ Training set -----------------------------\\n\")\n",
        "print(f\"train_images.shape  =  {train_images.shape}\\n\")\n",
        "print(f\"len(train_labels)  =  {len(train_labels)}\\n\")\n",
        "print(f\"train_labels  =  {train_labels}\\n\")\n",
        "\n",
        "print(\"------------------------------ Validation set -----------------------------\\n\")\n",
        "print(f\"validate_images.shape  =  {validate_images.shape}\\n\")\n",
        "print(f\"len(validate_labels)  =  {len(validate_labels)}\\n\")\n",
        "print(f\"validate_labels  =  {validate_labels}\\n\")\n",
        "\n",
        "print(\"------------------------------ Test set -----------------------------\\n\")\n",
        "print(f\"test_images.shape  =  {test_images.shape}\\n\")\n",
        "print(f\"len(test_labels)  =  {len(test_labels)}\\n\")\n",
        "print(f\"test_labels  =  {test_labels}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tQsqZW02WXLh"
      },
      "outputs": [],
      "source": [
        "# Visualize an image in the dataset\n",
        "visualize_image(train_images[100].reshape(28, 28), train_labels[100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7v6xAmiUG9v"
      },
      "source": [
        "**The network architecture**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LmNs8Q6oUH3H"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(26, activation=\"softmax\")\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uIJMYAzUNMH"
      },
      "source": [
        "**The compilation step**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NLaBP5pZUN3J"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExBznL1ZUYzw"
      },
      "source": [
        "**\"Fitting\" the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cQXKl2lEUccB"
      },
      "outputs": [],
      "source": [
        "history_part2 = model.fit(train_images, train_labels, epochs=5, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rGbwAcvJ79Kx"
      },
      "outputs": [],
      "source": [
        "## Visualize the accuracy and loss\n",
        "\n",
        "plt.plot(history_part2.history['accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history_part2.history['loss'], color='red')\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VW7bmRZhUgHv"
      },
      "source": [
        "**Using the model to make predictions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xIhmQ8QdUg8Z"
      },
      "outputs": [],
      "source": [
        "test_digits = test_images[0:10]\n",
        "\n",
        "predictions = model.predict(test_digits)\n",
        "\n",
        "print(f\"predictions[0]  =  {predictions[0]}\\n\")\n",
        "print(f\"predictions[0].argmax()  =  {predictions[0].argmax()}\\n\")\n",
        "print(f\"predictions[0][0]  =  {predictions[0][0]}\\n\")\n",
        "print(f\"test_labels[0]  =  {test_labels[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23uQ9L9gUmSn"
      },
      "source": [
        "**Evaluating the model on new data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mcf18Sa6UpNI"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f\"test_acc: {test_acc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcYP6MV-hkV-"
      },
      "source": [
        "## Answer to question 2 and 3:\n",
        "As can be seen, the accuracy on the test set is nearly 90%.\n",
        "\n",
        "If we compare this model to the previous one (MNIST dataset), the accuracy of the current model with the EMNIST Letters dataset is about **8% lower**. As a result, the current neural network is unable to perfectly capture information from the EMNIST Letters dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teO4s6fyiyAu"
      },
      "source": [
        "## Question 4\n",
        "The Keras examples include a Simple MNIST convnet. Note the accuracy obtained by that code compared to the previous example from Chollet.\n",
        "Apply the same architecture to the EMNIST Letters data. (Again, you are welcome to implement an equivalent architecture in PyTorch instead). What accuracy do you achieve? How does this compare with the accuracy for the MNIST? How does it compare with the accuracy for EMNIST that you saw with a Dense network in step (3)?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_TBLb9fwiBwD"
      },
      "outputs": [],
      "source": [
        "# Delete the contents of the log directory\n",
        "# remove_dir_contents(logs_dir)\n",
        "\n",
        "# Delete the contents of the model directory\n",
        "# remove_dir_contents(models_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ehYuBWe-mYMW"
      },
      "outputs": [],
      "source": [
        "# load emnist dataset into training, validation, and test sets\n",
        "(train_images, train_labels), (validate_images, validate_labels), (test_images, test_labels) = emnist_load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KEdOoRI43STI"
      },
      "outputs": [],
      "source": [
        "# Make sure images have shape (28, 28, 1)\n",
        "train_images = train_images.reshape((-1, 28, 28, 1))\n",
        "test_images = test_images.reshape((-1, 28, 28, 1))\n",
        "validate_images = validate_images.reshape((-1, 28, 28, 1))\n",
        "\n",
        "print(\"train_images shape:\", train_images.shape)\n",
        "print(train_images.shape[0], \"train samples\")\n",
        "print(test_images.shape[0], \"test samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0DfDqTZgNGqG"
      },
      "outputs": [],
      "source": [
        "# Visualize an image in the dataset\n",
        "visualize_image(train_images[100], train_labels[100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPtGUtysjhd1"
      },
      "source": [
        "**Build the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LtZ7gU3Njh_J"
      },
      "outputs": [],
      "source": [
        "# Model / data parameters\n",
        "num_classes = 26\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BN3Q85URkJ0n"
      },
      "source": [
        "**Train the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "p5emW3H1kJg6"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "epochs = 15\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "logdir = os.path.join(logs_dir, \"logs_q5\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "\n",
        "model.fit(train_images, train_labels, batch_size=batch_size, epochs=epochs, validation_data=(validate_images, validate_labels), callbacks=[tensorboard_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8mTpcMHw0sf1"
      },
      "outputs": [],
      "source": [
        "logdir = os.path.join(logs_dir, \"logs_q5\")\n",
        "%tensorboard --port 6004 --logdir $logdir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDVbJ78tkOTI"
      },
      "source": [
        "**Evaluate the trained model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SS-uKHcAkPKW"
      },
      "outputs": [],
      "source": [
        "score = model.evaluate(test_images, test_labels, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-6vjR1uqemT"
      },
      "source": [
        "## Answer to question 4 (Part 1)\n",
        "When we compare the accuracy of FCNN and CNN on the MNIST dataset, the CNN network outperforms FCNN by about 1%, according to the Simple MNIST convnet and the Simple Multilayer Perceptron from Francois Chollet.\n",
        "\n",
        "-\n",
        "\n",
        "We obtain nearly 93% accuracy if we utilize the CNN network and train it on the EMNIST Letters data after applying the same architecture as Francois Chollet's Simple MNIST convnet example.\n",
        "\n",
        "-\n",
        "\n",
        "If we compare the accuracy of the CNN network on the EMNIST Letters data and the MNIST data, we can see that the model's accuracy on the EMNIST Letters data is 93% while the model's accuracy on the MNIST data is 99%.\n",
        "\n",
        "-\n",
        "\n",
        "Using the EMNIST Letters data, the CNN model outperforms the FCNN model by over 3%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cu08aLy8yiSd"
      },
      "source": [
        "# Part 2 - Main Event\n",
        "\n",
        "Part 2 deals with training our own Convolutional Neural Network to perform image recognition. As mentioned later on, each member trained at least two models in this section. If we were working on collab, the results were automatically dumped into Google Drive. We took the best model based off of all of the training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3R1Svjy4gLN"
      },
      "source": [
        "## Question 5\n",
        "Add TensorBoard support to the CNN model you run in Part 1, and add TensorBoard to your notebook to visualize the training process.\n",
        "\n",
        "We are adding TensorBoard to hopefully avoid running into dead-ends while training. Due to the training process slowing down drastically, it is imperative that we are able to catch mistakes early.\n",
        "\n",
        "-\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "***We have added TensorBoard support to the previous part.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjkzSxgj453N"
      },
      "source": [
        "## Question 6\n",
        "\n",
        "With the baseline CNN, we have to experiment and try different architectures to obtain the highest accuracy possible for the validation set.\n",
        "\n",
        "For this stage, each member of the team trained multiple models with different parameters. We then proceeded to compare our accuracies in order to find the best model.\n",
        "\n",
        "The final model we settled is shown below. This model produced the best accuracy out of our individual attempts, and also did not take as long to train as some other models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GE2zWw0Ap9AJ"
      },
      "outputs": [],
      "source": [
        "# load emnist dataset into training, validation, and test sets\n",
        "(train_images, train_labels), (validate_images, validate_labels), (test_images, test_labels) = emnist_load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_Y7MmHAlrSvy"
      },
      "outputs": [],
      "source": [
        "# Make sure images have shape (28, 28, 1)\n",
        "train_images = train_images.reshape((-1, 28, 28, 1))\n",
        "test_images = test_images.reshape((-1, 28, 28, 1))\n",
        "validate_images = validate_images.reshape((-1, 28, 28, 1))\n",
        "\n",
        "print(\"train_images shape:\", train_images.shape)\n",
        "print(train_images.shape[0], \"train samples\")\n",
        "print(test_images.shape[0], \"test samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "u7cBkOivT88a"
      },
      "outputs": [],
      "source": [
        "# Visualize an image in the dataset\n",
        "visualize_image(train_images[100], train_labels[100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhTWZY1lsVje"
      },
      "source": [
        "**Build the Model**\n",
        "\n",
        "During our tuning phase, we edited this code block to try different hyperparameters to obtain the highest accuracy.\n",
        "\n",
        "The model built below was deemed to be the best model from our training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nPf0bRZjhi4q"
      },
      "outputs": [],
      "source": [
        "# Model / data parameters\n",
        "num_classes = 26\n",
        "input_shape = (28, 28, 1)\n",
        "epochs = 15\n",
        "batch_size = 256\n",
        "\n",
        "# This model's name is used to answer the following questions in parts 2 and 3.\n",
        "pretrained_model_name = f\"model_ep_{epochs}_bs_{batch_size}_adam\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sLtIBK9msWcv"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential(\n",
        "    [keras.Input(shape=input_shape),\n",
        "    layers.Conv2D(64, kernel_size=(5, 5), activation=\"relu\"),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Conv2D(128, kernel_size=(3, 3), activation=\"relu\"),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(2048, activation=\"relu\"),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1024, activation=\"relu\"),\n",
        "    layers.Dense(num_classes, activation=\"softmax\")]\n",
        "    )\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.0004),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Use the ModelCheckpoint callback to train the model and save the best model in terms of validation accuracy.\n",
        "checkpoint_filepath = os.path.join(models_dir, f'{pretrained_model_name}.h5')\n",
        "checkpoint = ModelCheckpoint(checkpoint_filepath, monitor='val_accuracy', mode=\"max\", save_best_only=True)\n",
        "\n",
        "# Use the TensorBoard callback to save logs\n",
        "logdir = os.path.join(logs_dir, \"logs_q6\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "\n",
        "history = model.fit(x=train_images,y=train_labels,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "\n",
        "                    validation_data=(validate_images, validate_labels),\n",
        "                    callbacks=[tensorboard_callback, checkpoint])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0bH5ui53xpz"
      },
      "source": [
        "**Logging**\n",
        "\n",
        "In order to retain the logs created while building, we set up a logdir in a shared Google Drive. The following block will dump the logs in said drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Vd2u-hmq4rOI"
      },
      "outputs": [],
      "source": [
        "logdir = os.path.join(logs_dir, \"logs_q6\")\n",
        "\n",
        "%tensorboard --port 6003 --logdir  $logdir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woMRLE3B3_qN"
      },
      "source": [
        "## Question 7:\n",
        "Load and Evaluate the Model\n",
        "\n",
        "-\n",
        "\n",
        "Now that our model is built and saved to the drive, we are able to automatically load the best model. After we load the model, we will then evaluate the model on the test set to see the test accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-WfzH5fTwhBy"
      },
      "outputs": [],
      "source": [
        "# Load the best model and evaluate on the test set\n",
        "\n",
        "checkpoint_filepath = os.path.join(models_dir, f'{pretrained_model_name}.h5')\n",
        "best_model = keras.models.load_model(checkpoint_filepath)\n",
        "test_loss, test_acc = best_model.evaluate(test_images, test_labels)\n",
        "print(f'Model - Test accuracy: {test_acc}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqg1PM0VIJfi"
      },
      "source": [
        "# Part 3: Transfer Learning\n",
        "\n",
        "Here, we will be using transfer learning to see if our model can properly evaluate different datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VyXmwyV6h0f"
      },
      "source": [
        "## Question 8:\n",
        "The process of transfer learning can be used to apply an existing model to a new dataset. See Transfer learning & fine-tuning in the Keras Developer Guide or the Transfer Learning for Computer Vision Tutorial in the PyTorch Tutorials.\n",
        "The images in the Binary Alphadigits dataset are a different size from those in EMNIST Letters. Use a function like tf.image.resize_with_pad(), PIL.ImageOps.pad(), or the PyTorch torchvision.transforms.Resize class to resize them into the right format for the network you trained in Part 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joyzq1I7-7ec"
      },
      "source": [
        "### Loading New Dataset\n",
        "\n",
        "Here, we are going to load the new dataset, and visualize it.\n",
        "\n",
        "This will be the dataset that we use for transfer learning with our trained model from earlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YBBHhUrx6qL3"
      },
      "outputs": [],
      "source": [
        "#it only has two files, btw\n",
        "with np.load(os.path.join(data_dir, \"binaryalphadigs.npz\")) as f:\n",
        "  (ad_images, ad_labels) = f[\"images\"], f[\"labels\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IXKtMNypvA_t"
      },
      "outputs": [],
      "source": [
        "# what is the number, size, and shape of this dataset?\n",
        "print('img shape ', ad_images.shape)\n",
        "print('lbl shape ', ad_labels.shape)\n",
        "\n",
        "print('trim unused class from labels')\n",
        "# Remove first class (index 0)\n",
        "ad_labels = np.delete(ad_labels, 0, axis=1)\n",
        "\n",
        "# what is the number, size, and shape of this dataset after removing the first class?\n",
        "print('img shape ', ad_images.shape)\n",
        "print('lbl shape ', ad_labels.shape)\n",
        "\n",
        "print('img zero ', ad_images[0])\n",
        "print('lbl zero ', ad_labels[0])\n",
        "\n",
        "print('img zero shape ', ad_images[0].shape)\n",
        "print('lbl zero shape ', ad_labels[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-glWJ55f7ppJ"
      },
      "outputs": [],
      "source": [
        "# Visualize an image in the dataset\n",
        "visualize_image(ad_images[1000].reshape(20, 16), ad_labels[1000])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQfshIUSvDdw"
      },
      "source": [
        "NOTE FROM THE ASSIGNMENT:<br>\n",
        "**Note, however, that the resolution of the images is different in this dataset: 20×16 rather than 28×28.**\n",
        "<br>\n",
        "So we have to resize our \"images\" https://www.tensorflow.org/api_docs/python/tf/image/resize_with_pad.\n",
        "\n",
        "The end result will be an array that will match the dimensions of our original array. This will be compatible with our model from earlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "M5I4_ec5-8CT"
      },
      "outputs": [],
      "source": [
        "def preprocess_image(target_image):\n",
        "    reshaped_img = tf.reshape(tf.convert_to_tensor(target_image, dtype=tf.float32), (20, 16, 1))\n",
        "    return tf.image.resize_with_pad(\n",
        "        image=reshaped_img,\n",
        "        target_height=28,\n",
        "        target_width=28,\n",
        "        method=tf.image.ResizeMethod.NEAREST_NEIGHBOR\n",
        "    )\n",
        "\n",
        "def preprocess_batch(images_batch):\n",
        "    return tf.map_fn(preprocess_image, images_batch, dtype=tf.float32)\n",
        "\n",
        "\n",
        "# Convert the dataset to TensorFlow tensors\n",
        "ad_images = tf.convert_to_tensor(ad_images, dtype=tf.float32)\n",
        "\n",
        "# resize the images\n",
        "ad_images_processed = preprocess_batch(ad_images)\n",
        "\n",
        "# Convert the dataset to numpy array\n",
        "ad_images_processed = ad_images_processed.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HBzFGh2EZkrF"
      },
      "outputs": [],
      "source": [
        "visualize_image(ad_images_processed[100], ad_labels[100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukb7b4_8uJB-"
      },
      "source": [
        "## Question 9:\n",
        "Is the model you trained in Part 2 capable of recognizing letters from this new dataset?\n",
        "\n",
        "-\n",
        "## Using Model from Checkpoint\n",
        "Now, with the model in hand from the saved checkpoint, let's take the weights out and evaluate on the new dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DOVxrBk8NY6b"
      },
      "outputs": [],
      "source": [
        "# Split data into 80% train and 20% test subsets\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(ad_images_processed, ad_labels, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6W3P6OHjtvnr"
      },
      "outputs": [],
      "source": [
        "# Load our pre-trained model based on prev evaluation\n",
        "checkpoint_filepath = os.path.join(models_dir, f'{pretrained_model_name}.h5')\n",
        "\n",
        "pretrained_model = keras.models.load_model(checkpoint_filepath)\n",
        "\n",
        "pretrained_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mInLlZ93Ng6q"
      },
      "outputs": [],
      "source": [
        "# Evaluate our pretrained model on the test set of the new dataset\n",
        "test_loss, test_acc = pretrained_model.evaluate(test_images, test_labels)\n",
        "print(f'Model - Test accuracy: {test_acc}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yqKgHQcTLjK"
      },
      "source": [
        "## Answer to question 9:\n",
        "As can be seen, the accuracy on the test set is 81%. So, the model is able to recognize the images in the new dataset. However, the accuracy is not as good as the original dataset (EMNIST Dataset)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1sVps7mHo7D"
      },
      "source": [
        "## Question 10:\n",
        "Can you improve the performance on this dataset by adding additional trainable layers and fine-tuning the network?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZyubqiqQoO9"
      },
      "source": [
        "### Train_Test_split technique\n",
        "\n",
        "Here, we are applying the train/test split technique in order to prevent overfitting of the model to the entire dataset. We also use a validation set, which can act as an additional hyperparamter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uHMlzfIiNqvT"
      },
      "outputs": [],
      "source": [
        "# Load our pre-trained model based on prev evaluation\n",
        "checkpoint_filepath = os.path.join(models_dir, f'{pretrained_model_name}.h5')\n",
        "pretrained_model = keras.models.load_model(checkpoint_filepath)\n",
        "\n",
        "# Remove the last layer(s) - We only remove the output layer.\n",
        "pretrained_model.pop()\n",
        "\n",
        "# Make sure all layers in the pre-trained model are not trainable\n",
        "for layer in pretrained_model.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "d4NaG2lQuLUC"
      },
      "outputs": [],
      "source": [
        "# Model / data parameters\n",
        "num_classes = 26\n",
        "epochs = 15\n",
        "batch_size = 8\n",
        "new_ds_best_model_name = f\"new_ds_model_ep_{epochs}_bs_{batch_size}_adam\"\n",
        "\n",
        "# Create a new model with the modified pre-trained model and the new classification layer\n",
        "new_model = tf.keras.Sequential([\n",
        "    pretrained_model,\n",
        "    # layers.Dense(1024, activation='relu'),\n",
        "    # layers.Dropout(0.5),\n",
        "    # layers.Dense(512, activation='relu'),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(num_classes, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Train the model with the ModelCheckpoint callback to save the best model in terms of validation accuracy\n",
        "checkpoint_filepath = os.path.join(models_dir, f'{new_ds_best_model_name}.h5')\n",
        "checkpoint = ModelCheckpoint(checkpoint_filepath, monitor='val_accuracy', mode=\"max\", save_best_only=True)\n",
        "\n",
        "# Use the TensorBoard callback to save logs\n",
        "logdir = os.path.join(logs_dir, \"logs_q10\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "\n",
        "# Compile the new model\n",
        "new_model.compile(optimizer=Adam(learning_rate=0.0005), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "# Train the new model on the new dataset\n",
        "new_model.fit(train_images, train_labels, epochs=epochs, batch_size=batch_size, validation_split=0.3, callbacks=[tensorboard_callback, checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pHkyohaA7j8l"
      },
      "outputs": [],
      "source": [
        "logdir = os.path.join(logs_dir, \"logs_q10\")\n",
        "\n",
        "%tensorboard --port 6002 --logdir $logdir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "o1LnhAoBOPz3"
      },
      "outputs": [],
      "source": [
        "# Load the best model\n",
        "checkpoint_filepath = os.path.join(models_dir, f'{new_ds_best_model_name}.h5')\n",
        "best_model = keras.models.load_model(checkpoint_filepath)\n",
        "\n",
        "# Evaluate our model on the test set\n",
        "test_loss, test_acc = best_model.evaluate(test_images, test_labels)\n",
        "print(f'Model - Test accuracy: {test_acc}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcvhFUyOHiMN"
      },
      "source": [
        "As demonstrated above, using a pre-trained model (trained on the EMNIST Dataset) and re-training only the output layer improved accuracy from 81% to 92%. Training the output layer with the Binary Alphadigits dataset and adjusting hyperparameters appear to have aided in the accuracy improvement.\n",
        "\n",
        "-\n",
        "\n",
        "In this evaluation, we use the train/test split technique to evaluate the model. However, due to the short size of our dataset, we will additionally utilize the k-fold cross validation technique to evaluate the network and obtain a more accurate result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92-IYEO-Qwxi"
      },
      "source": [
        "### K-fold cross validation technique\n",
        "\n",
        "K-fold cross is a unique technique that can evaluate the performance of the model when given new data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6qJ29W1TQ038"
      },
      "outputs": [],
      "source": [
        "# Load our pre-trained model based on prev evaluation\n",
        "checkpoint_filepath = os.path.join(models_dir, f'{pretrained_model_name}.h5')\n",
        "pretrained_model = keras.models.load_model(checkpoint_filepath)\n",
        "\n",
        "# Remove the last layer(s)\n",
        "pretrained_model.pop()\n",
        "\n",
        "# Make sure all layers in the pre-trained model are not trainable\n",
        "for layer in pretrained_model.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jnaqyVV7Q3GA"
      },
      "outputs": [],
      "source": [
        "# Model / data parameters\n",
        "num_classes = 26\n",
        "\n",
        "# Helper function to create a model\n",
        "def create_model():\n",
        "  # Create a new model with the modified pre-trained model and the new classification layer\n",
        "  new_model = tf.keras.Sequential([\n",
        "      pretrained_model,\n",
        "      # layers.Dense(1024, activation='relu'),\n",
        "      # layers.Dropout(0.5),\n",
        "      # layers.Dense(512, activation='relu'),\n",
        "      layers.Dropout(0.3),\n",
        "      layers.Dense(num_classes, activation=\"softmax\")\n",
        "  ])\n",
        "\n",
        "  # Compile the new model\n",
        "  new_model.compile(optimizer=Adam(learning_rate=0.0005), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "  return new_model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6TB-1xb-8Gv"
      },
      "source": [
        "## Decisions\n",
        "\n",
        "Similar to training a model, we had to make some decisions for the k-fold cross validation.\n",
        "\n",
        "We settled on 5 folds, 15 epochs, and a batch_size of 8 because the combination produced the best results. We tried out other hyperparameters but could not match the high accuracy produced by this combination.\n",
        "\n",
        "For the folds specifically, we did try 10 folds and 15 folds. Since the dataset is so small, however, we settled on 5 folds as it was sufficient enough."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vOOIO5LbRF5z"
      },
      "outputs": [],
      "source": [
        "k = 5  # Number of folds\n",
        "epochs = 15\n",
        "batch_size = 8\n",
        "\n",
        "kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "\n",
        "scores = []\n",
        "fold = 1\n",
        "best_val_accuracy = 0\n",
        "\n",
        "new_ds_best_model_name = f\"new_ds_model_k_fold_cross_val_ep_{epochs}_bs_{batch_size}_adam\"\n",
        "best_model_path = os.path.join(models_dir, f'{new_ds_best_model_name}.h5')\n",
        "\n",
        "for train_index, val_index in kfold.split(train_images, train_labels):\n",
        "    print(f\"Fold {fold}/{k}\")\n",
        "    X_train, X_val = train_images[train_index], train_images[val_index]\n",
        "    y_train, y_val = train_labels[train_index], train_labels[val_index]\n",
        "\n",
        "    model = create_model()\n",
        "\n",
        "    checkpoint = ModelCheckpoint(f\"best_model_fold_{fold}.h5\", monitor='val_accuracy', save_best_only=True, mode='max')\n",
        "\n",
        "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size, callbacks=[checkpoint])\n",
        "\n",
        "    # Load the best model for the current fold\n",
        "    best_fold_model = keras.models.load_model(f\"best_model_fold_{fold}.h5\")\n",
        "    val_score = best_fold_model.evaluate(X_val, y_val, verbose=0)\n",
        "    print(f\"Best validation accuracy for fold {fold}: {val_score[1]}\")\n",
        "\n",
        "    # Maintain the best model in terms of validation accuracy across all folds.\n",
        "    if val_score[1] > best_val_accuracy:\n",
        "        best_val_accuracy = val_score[1]\n",
        "        best_fold_model.save(best_model_path)\n",
        "\n",
        "    scores.append(val_score[1])\n",
        "    fold += 1\n",
        "\n",
        "average_val_accuracy = np.mean(scores)\n",
        "print(f\"Average validation accuracy across {k} folds: {average_val_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bZzV3ztdQ50f"
      },
      "outputs": [],
      "source": [
        "# Load the best model\n",
        "best_model = keras.models.load_model(best_model_path)\n",
        "\n",
        "# Evaluate our model on the test set\n",
        "test_loss, test_acc = best_model.evaluate(test_images, test_labels)\n",
        "print(f'Model - Test accuracy: {test_acc}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QE0nnxCuH3y3"
      },
      "source": [
        "Performance comparison:\n",
        "\n",
        "K-fold cross validation obtains 91% accuracy on the test set, which is roughly identical to train_test accuracy (92%)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPiDkbCaTr6C"
      },
      "source": [
        "## Answer to question 10:\n",
        "After removing the output layer from pretrained model and training a new model on the new dataset, we could achieve accuracy of nearly 91% on test set with 5-fold cross validation and train-test split techniques. As a result, the fine-tuned model is improved by approximately 10% compared to using only the pre-trained model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKuVdIpaJZdv"
      },
      "source": [
        "## Question 11:\n",
        "Compare the performance of the model you built in step (3) with the performance of a brand-new model trained only on the Binary AlphaDigits dataset.\n",
        "\n",
        "-\n",
        "\n",
        "Build a brand new model and train it on the Binary AlphaDigits dataset and evaluate it using 5-fold cross validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vdyA8DUU7kOk"
      },
      "outputs": [],
      "source": [
        "#code \"to load dataset\" included in case dataset not already loaded in notebook\n",
        "with np.load(os.path.join(data_dir, \"binaryalphadigs.npz\")) as f:\n",
        "  (ad_images, ad_labels) = f[\"images\"], f[\"labels\"]\n",
        "\n",
        "# Remove first class (index 0)\n",
        "ad_labels = np.delete(ad_labels, 0, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_3iur3yAgH9e"
      },
      "outputs": [],
      "source": [
        "def preprocess_image(target_image):\n",
        "    reshaped_img = tf.reshape(tf.convert_to_tensor(target_image, dtype=tf.float32), (20, 16, 1))\n",
        "    return tf.image.resize_with_pad(\n",
        "        image=reshaped_img,\n",
        "        target_height=28,\n",
        "        target_width=28,\n",
        "        method=tf.image.ResizeMethod.NEAREST_NEIGHBOR\n",
        "    )\n",
        "\n",
        "def preprocess_batch(images_batch):\n",
        "    return tf.map_fn(preprocess_image, images_batch, dtype=tf.float32)\n",
        "\n",
        "\n",
        "# Convert the dataset to TensorFlow tensors\n",
        "ad_images = tf.convert_to_tensor(ad_images, dtype=tf.float32)\n",
        "\n",
        "# resize the images\n",
        "ad_images_processed = preprocess_batch(ad_images)\n",
        "\n",
        "# Convert the dataset to numpy array\n",
        "ad_images_processed = ad_images_processed.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oQB_EmWWVueo"
      },
      "outputs": [],
      "source": [
        "# Split data into 80% train and 20% test subsets\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(ad_images_processed, ad_labels, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0XNitY5qd8H-"
      },
      "outputs": [],
      "source": [
        "# Model / data parameters\n",
        "num_classes = 26\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# Helper function to create a model\n",
        "def create_model():\n",
        "  ad_only_layers = tf.keras.Sequential(\n",
        "    [keras.Input(shape=input_shape),\n",
        "    layers.Conv2D(64, kernel_size=(5, 5), activation=\"relu\"),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Conv2D(128, kernel_size=(3, 3), activation=\"relu\"),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1024, activation=\"relu\"),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(num_classes, activation=\"softmax\")]\n",
        "    )\n",
        "\n",
        "  # Compile the new model\n",
        "  ad_only_layers.compile(optimizer=Adam(learning_rate=0.001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "  return ad_only_layers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8Flmbh_VV2Jz"
      },
      "outputs": [],
      "source": [
        "k = 5  # Number of folds\n",
        "epochs = 10\n",
        "batch_size = 8\n",
        "\n",
        "kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "scores = []\n",
        "fold = 1\n",
        "best_val_accuracy = 0\n",
        "\n",
        "new_ds_best_model_name = f\"new_ds_model_k_fold_cross_val_ep_{epochs}_bs_{batch_size}_adam_without_transfer_learning\"\n",
        "best_model_path = os.path.join(models_dir, f'{new_ds_best_model_name}.h5')\n",
        "\n",
        "for train_index, val_index in kfold.split(train_images, train_labels):\n",
        "    print(f\"Fold {fold}/{k}\")\n",
        "    X_train, X_val = train_images[train_index], train_images[val_index]\n",
        "    y_train, y_val = train_labels[train_index], train_labels[val_index]\n",
        "\n",
        "    model = create_model()\n",
        "\n",
        "    checkpoint = ModelCheckpoint(f\"best_model_fold_{fold}.h5\", monitor='val_accuracy', save_best_only=True, mode='max')\n",
        "\n",
        "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size, callbacks=[checkpoint])\n",
        "\n",
        "    # Load the best model for the current fold\n",
        "    best_fold_model = keras.models.load_model(f\"best_model_fold_{fold}.h5\")\n",
        "    val_score = best_fold_model.evaluate(X_val, y_val, verbose=0)\n",
        "    print(f\"Best validation accuracy for fold {fold}: {val_score[1]}\")\n",
        "\n",
        "    # Maintain the best model in terms of validation accuracy across all folds.\n",
        "    if val_score[1] > best_val_accuracy:\n",
        "        best_val_accuracy = val_score[1]\n",
        "        best_fold_model.save(best_model_path)\n",
        "\n",
        "    scores.append(val_score[1])\n",
        "    fold += 1\n",
        "\n",
        "average_val_accuracy = np.mean(scores)\n",
        "print(f\"Average validation accuracy across {k} folds: {average_val_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WjesrS6uW0bz"
      },
      "outputs": [],
      "source": [
        "# Load the best model\n",
        "best_model = keras.models.load_model(best_model_path)\n",
        "\n",
        "# Evaluate our model on the test set-\n",
        "test_loss, test_acc = best_model.evaluate(test_images, test_labels)\n",
        "print(f'Model - Test accuracy: {test_acc}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6MK_ia1Ue65"
      },
      "source": [
        "## Answer to question 11:\n",
        "As can be observed, the brand-new model trained solely on the Binary AlphaDigits dataset achieves a test-set accuracy of nearly 83%. As a result, the brand new model outperforms the pre-trained model by 2%. However, the accuracy of the brand new model is around 8% lower than that of the fine-tuned model, which is based on the pre-trained model."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}